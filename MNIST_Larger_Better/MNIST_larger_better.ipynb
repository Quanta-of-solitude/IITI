{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>IITI MNIST from LargerDataset, skb</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LOADING training andd test dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train), (X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimension of inputs be 28x28x1 grayscale\n",
    "input_shape = (28,28,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>images are to be reshaped  and scaled to have values between 0 and 1 range </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the training images.\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_train = X_train/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the test images\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)\n",
    "X_test = X_test/255\n",
    "#X_test = X_test.reshape(X_test.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "#changing y_train and y_test to categorical values (binary)\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "X_test shape:  (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "print('X_test shape: ',X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Making the model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(64,(3,3),activation=\"relu\",input_shape=input_shape))\n",
    "classifier.add(MaxPooling2D(2,2))\n",
    "\n",
    "classifier.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(128,activation=\"relu\"))\n",
    "\n",
    "\n",
    "classifier.add(Dense(10,activation = \"softmax\"))\n",
    "\n",
    "classifier.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 26s - loss: 0.1968 - acc: 0.9424 - val_loss: 0.0753 - val_acc: 0.9761\n",
      "Epoch 2/20\n",
      " - 25s - loss: 0.0520 - acc: 0.9840 - val_loss: 0.0465 - val_acc: 0.9848\n",
      "Epoch 3/20\n",
      " - 23s - loss: 0.0365 - acc: 0.9887 - val_loss: 0.0311 - val_acc: 0.9895\n",
      "Epoch 4/20\n",
      " - 24s - loss: 0.0254 - acc: 0.9917 - val_loss: 0.0376 - val_acc: 0.9883\n",
      "Epoch 5/20\n",
      " - 24s - loss: 0.0213 - acc: 0.9934 - val_loss: 0.0276 - val_acc: 0.9909\n",
      "Epoch 6/20\n",
      " - 23s - loss: 0.0153 - acc: 0.9950 - val_loss: 0.0278 - val_acc: 0.9911\n",
      "Epoch 7/20\n",
      " - 23s - loss: 0.0134 - acc: 0.9957 - val_loss: 0.0272 - val_acc: 0.9903\n",
      "Epoch 8/20\n",
      " - 23s - loss: 0.0108 - acc: 0.9965 - val_loss: 0.0284 - val_acc: 0.9914\n",
      "Epoch 9/20\n",
      " - 22s - loss: 0.0081 - acc: 0.9973 - val_loss: 0.0366 - val_acc: 0.9896\n",
      "Epoch 10/20\n",
      " - 22s - loss: 0.0080 - acc: 0.9972 - val_loss: 0.0323 - val_acc: 0.9920\n",
      "Epoch 11/20\n",
      " - 23s - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0350 - val_acc: 0.9901\n",
      "Epoch 12/20\n",
      " - 22s - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0395 - val_acc: 0.9909\n",
      "Epoch 13/20\n",
      " - 22s - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0341 - val_acc: 0.9907\n",
      "Epoch 14/20\n",
      " - 22s - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0315 - val_acc: 0.9913\n",
      "Epoch 15/20\n",
      " - 22s - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0320 - val_acc: 0.9920\n",
      "Epoch 16/20\n",
      " - 23s - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0271 - val_acc: 0.9927\n",
      "Epoch 17/20\n",
      " - 23s - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0307 - val_acc: 0.9930\n",
      "Epoch 18/20\n",
      " - 23s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0344 - val_acc: 0.9921\n",
      "Epoch 19/20\n",
      " - 23s - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0316 - val_acc: 0.9938\n",
      "Epoch 20/20\n",
      " - 23s - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0369 - val_acc: 0.9917\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(X_train,y_train,batch_size=128,\n",
    "                         epochs=20,\n",
    "                         validation_data=(X_test,y_test),\n",
    "                         verbose=2\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"mnist_larger_skb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.036919978970984514\n",
      "Accuracy:  0.9917\n"
     ]
    }
   ],
   "source": [
    "datas = classifier.evaluate(X_test,y_test,verbose=2)\n",
    "print(\"Loss: \",datas[0])\n",
    "print(\"Accuracy: \",datas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
